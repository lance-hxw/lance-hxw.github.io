# 主从复制
单向复制， 读写分离，一主多从
配置简单
缺点： 不能故障转移， 单点故障

# 哨兵模式 sentinel， 一般不用， 一般是集群三主三从这样
基于主从复制，加上故障自动转移
即： 
- 哨兵节点持续监控主节点健康信息
- 主节点故障， 发生选举，出现新的主节点
- 然后通知其他节点新主节点
redis的哨兵模式类似zk， 但是是专门实现的，用于故障检测和故障转移
哨兵节点是一个特殊状态的redis实例，其代码集成在redis中了
一个哨兵会对其监控的所有节点发送心跳包， 要求响应，以检测节点状态
## 哨兵选举算法
- 主观下线：当一个哨兵与一个节点失去联系
- 客观下线：哨兵集群交流后判定节点确实故障（而不是某条连接出现问题
	- 如果下线的是从节点或者sentinel节点，无所谓
	- 如果主节点下线，进行选举
### 选举算法
每个哨兵首先提议自己为哨兵leader， 并请求其他哨兵
其他哨兵同意其接受到的第一个请求，拒绝其他请求
只要得票严格超过半数， 或者超过设置的阈值，就成功变成leader
当一个哨兵变成leader， 就可以从redis集群中选出主节点，挑选逻辑为：
- 去掉所有已经故障节点
- 优先选择提前设置的slave-priority优先级最大的从节点，不存在则继续
- 选择复制偏移量最大的节点，不存在则继续
- 选择runid最小的
这个过程与zab选举类似但不同

# 集群模式 Cluster
- 数据分片，数据分别存在不同节点
- 去中心化：不会单点故障
- 每个节点都可以有自己的从节点，进行故障转移
	- **集群模式的故障转移由集群的控制器进行，不需要单独的哨兵线程**
- 可以线性拓展
- 比较麻烦
关键技术：
- hash slot， 用于数据分配
	- 分配可以平均分配，也可以手动分配，手动分配要分配完所有slot
- 一致性：最终一致性

## 优缺点
- 高可用，叠加主从复制（即集群三主三从）
- 高性能，分片集群吞吐量高
- 扩展性好：支持水平拓展，还可以设置代理节点
主要缺点：
- 维护和部署复杂， 需要考虑分片规则的合理性，主从配置和故障处理
- 同步问题
- 分片限制：数据在不同节点上

# 主从同步过程：利用两个缓冲区和一个offset实现

## 缓冲区
replication buffer 复制缓冲区，可以缓存完全同步期间的主库执行命令
- 主节点上，对每个从节点都设置一个，只在连接存在时临时存在
- 主要有两个作用
	- 普通连接过程中：主节点运行一个命令后，将命令写入所有从节点的复制缓冲区，异步将命令发送到从节点
	- 全量同步过程中：用于缓存全量同步RDB传输期间的命令， RDB传输完成后，发送到从节点。
repl_backlog_buffer 复制积压缓冲区，增量同步中，处理主从短暂断开时，主库命令
- 这个玩意是个环形的， 所有从库共享一个
- 用于增量同步，记录最近的写命令记录
- 持久存在
- 使用复制偏移量机制确定从节点需要的数据位置
	- 如果从节点偏移太古老，不再环中，就全量同步
- 如果size太小会频繁触发全量同步， 应该设置大一些
## 复制积压缓冲区的 主从偏移量
偏移量是复制积压缓冲区位置的递增偏移量，代表已经处理的命令总量
主server用master_repl_offset标记自己写到的位置
从server用slave_repl_offset记录自己读到的位置

从节点默认每秒发送REPLCONF ACK汇报自己的复制偏移量
主节点根据这个汇报得知从节点的复制进度

这东西没有溢出风险的， 一直递增也没事

## RUN id
redis服务器启动时生成， 40字符长， 无论主从都有， 是任何一个redis实例的唯一标志符
- 在主从复制场景下：主节点用自己的runid作为replication id
	- 从节点在复制过程中用replication id 来标识连接，而不是自己的runid
	- 从节点会一直保存这个replication id
	- 主节点重启，复制id就变了
	- 如果节点被选举为主节点，会保留原来主节点的replication id作为secondary Id， 然后产生一个新的replication id
		- 这个secondary id 可以用于辅助其余从节点的更新工作
			- 而不是“检测replication id变动， 直接全量同步”

## 如何判定需要全量同步：偏移量非法
- 超出范围：即slave_repl_offset\<master_repl_offset-backlog_size
	- 或者比主节点还大，说明错乱了要纠正
- run id 无法识别， 说明不是当前主节点的副本
- 没有开启复制积压缓冲区
- 首次连接的PSYNC 发出offset是-1

## 完全同步
基于FULLRESYNC
时机：
- 主从首次连接时
- 从server数据丢失
- 主server数据变化，与从节点差异太大
	- 即从节点的偏移量已经不在环形缓冲区可以恢复的区域中了
流程：
- 从服务器发出FULLRESYNC， 请求同步
	- 这里会先发一个psync和偏移量（如果第一次是-1），偏移量对不上
		- 然后主server发出全量同步回应，并给出runid和offset
- 主server接受sync后，生成RDB文件，然后传输RDB
	- 主server在这个期间，将所有接受到的写命令写到replication buffer
- 从server接受RDB，清空当前数据，载入RDB
- 从服务器载入完成后，接受replication buffer中的命令，进行同步

## 增量同步
基于PSYNC，使用run id和offset实现
时机：
- 正常状态下主从同步
- 短暂下线的同步
流程：
- 从服务器发出psync，runid，offset
- 主server同意，然后开始传命令
# redis主从/集群 数据一致性？
都是AP， 牺牲了强一致性