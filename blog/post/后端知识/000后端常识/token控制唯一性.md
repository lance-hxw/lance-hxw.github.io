即一个事件会消费这个token, 要保证事件处理和token消费的原子性, 形成一个分布式事务.
- 实际场景是: 用户准备提交订单, 此时请求一次后端, 后端生成一个token, 写到redis中并传给前端, 请求过来后, 如果这个token已经不在了, 就不处理

这本质是一个使用分布式事务实现接口防重
- 也可以传id过去, 然后处理的时候设置一个过期时间较长的key, 过滤后续请求
# 朴素方案

直接删token, 然后执行: 如果执行失败会导致丢失
直接执行然后删token: 要求分布式幂等性

# \[分布式锁方案]使用token+processing 作为key 使用set nx对token上锁

使用lua脚本判断token是否存在, 然后SET_NX processing, 这个思路也是, 将正在消费的标记出来.

配合短过期时间, 如果之前的执行失败了, processing key过期就可以被重新消费

但是做不了重试次数限制(不过由于有短过期时间, 可以防止并发, 加上给token设置一个合理过期时间, 一致不能执行也可以失败)

注意:
- 这个 token可以用hash组织, 这样变成一个单体, 避免跨slot
	- 同时可以记录更多信息, 如重入次数, owner等, 更加安全
- 执行失败可以删除锁

# \[MQ]使用mq, 删完token后加MQ保证执行
MQ提供运行成功保证, 但是如果删完没提交到MQ怎么办
此时主要涉及事务持久化问题
此时主要思路是: 持久化意图, 然后实际执行

## redis内部可靠消费, 将正在消费的标记出来
搞两个队列, 主队列和processing队列

当接受请求时, 该服务端成为生成这, 使用lua脚本检测token存在, 若存在, 将一个msg放到主队列

消费者从主队列中消费, 消费时使用BRPOPLPUSH移动这个msg到processing队列, 然后反序列化尝试执行
若执行出错, 就进行重试, 使用额外kv存储, 将原来msg设置为不可用, 然后更新msg版本(一般用剩余重试次数表示不同就行), 然后再序列化放到主队列中

启动一个额外的线程维护processing队列, 发现msg在kv存储中不合法, 或者停留太久, 就清理掉, 或者放入死信队列等log


# 本地事务表
