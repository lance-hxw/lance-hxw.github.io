数据库给多客户端并发场景提供Isolation支持, 但是可串行化性能太差, 所以需要弱隔离级别
如果从可串行化出发, 可以这样理解:
- 可串行化: 全局锁, 只能有一个事务运行
- 弱隔离级别, 降低锁强度,长短, 大小:
	- X,S锁
	- 长时锁, 短时锁
		- 行锁, 谓词锁(Predicate lock) 
一般来说, 任何隔离等级都需要关注两个方向:
- 读与写的隔离
	- 如S锁, 不准写
	- 如MVCC, 版本控制
- 写与写的隔离
	- 如X锁, 不并发
# 两种实现隔离的方式
- 基于锁
- 基于MVCC
	- 每个事务开始时有一个递增的txid
	- 事务修改数据时, 不是修改以前的版本, 而是新增一个txid对应的版本
	- 每个事务只能访问其txid之前的版本
	- 写入时, 如果发现已经有>自己txid的版本, 说明出现了写写冲突
		- 这是冲突检测
	- mvcc的实现不是持久化的, 随着版本不再被事务依赖, 会被GC
# 读未提交 RU
最基础的情况下, 不加任何锁, 此时也存在最基础的问题: 脏读脏写
其中脏写是任何数据库都不能忍受的, 可以对要更改的对象加X锁, 但读的时候不加锁, 此时就是读未提交
## 解决问题
### 脏写: 覆盖未提交事务的值
- 如在a支付过程中, a账户存入1元, 导致扣款被覆盖成old value + 1
## 实现机制
对要修改的对象加X锁

# 读已提交 RC
## 解决的问题
### 脏读: 读取未提交事务中的中间状态
- 如读取一个支付过程, 此时一方扣钱另一方还没加钱
## 实现
- 解决 脏写: 直接用X锁
- 解决 脏读: 使用短S锁, 在有X锁时无法读
	- 这个短S锁是用来判断是否有事务在写
		- 而不是用于占用这个记录
	- 实际: mvcc获取最新已经提交版本
		- 如果只是rc, 那么mvcc只要两个版本
		- 持久化版本和正在修改的版本
			- 写是不能并发的, 所以不会有多个修改版本

基于锁的方式, 一个长时间写的事务会饿死其他读事务, 这在oltp场景几乎不可忍受

所以一般都用非锁的方式实现RC, 即MVCC
其主要思想是读历史值, 根据版本(事务id)判断应该读什么
# 可重复读与快照隔离
## 解决的问题: 不可重复读
或者说read skew, 即读的条件已经失效.

不可重复读一般来说不严重, 因为这一般都是暂时的, 只要最后收敛即可, 不过有的时候这是不可接受的
- 备份: 备份的时候如果将不一致的数据读出来dump, 那以后就永久不一致了
	- 而且备份的时间很长, 更容易出现这个问题
- 进行ap和完整性检查的时候, 同样时间很长, 此时分析和检查的结果就会出错

快照隔离能解决这个问题
# 快照隔离(MVCC)
每个事务都能获取一个特定时间点的一致性快照, 就可以实现, 在整个事务期间都从这个快照上读取, 不会被其他事务干扰

## 实现
- 写: 加X锁
- 读: 读写互不阻塞, 使用mvcc
	- SI的mvcc需要很多个已经提交的版本
	- 每个版本可以抽象成create by 和 deleted by, 当一个数据被一个tx写了新的版本, 他就去标记删除老版本
		- 不是立即删除是可能有更早的事务还依赖这个版本
		- gc的时候根据deleteby的txid和当前最小活跃tx的id决定是否进行gc
### mvcc的可见性原则
事务中的读取操作, 需要控制版本和事务的可见性, 保证事务能看到一致性视图
简单来说, 一个事务应该只能看\<txid的数据, 准确的说:
- 事务开始的时候, 所有还没有提交的事务的任何写入, 在本事务中都看不到
- 如果事务回滚, 那也看不到
- 更晚开始的事务也看不到
- 其他数据可见
这是基于txid的单调增性质, 即保证:
- txid更小的事务, 更早开始
- txid更大的事务, 更晚开始
同时, 如果一个版本被标记删除了, 但是deleteby的事务还没提交, 也是可见的

### mvcc的索引
由于涉及多个版本, mvcc的索引会更复杂
最朴素的, 可以用索引指向一个对象的所有版本, 然后用版本号过滤

实践中:
- 朴素版本的优化: 如果一个对象更新前后的数据都在一个页面, 就不用更新索引
- couchDB, boltdb等中使用了一种copy-on-write/append-only的B树结构, 即每次修改都会导致叶子对应的一条路径的全部修改, 然后创建一个新的根, 作为版本的快照, 这个根能访问的数据都是一个版本上的.
## 命名
pg和mysql中实现了SI, 并将其称为RR, Oracle称其为S

[[并发控制与数据库异象]]

# 更新丢失
对单个对象, 读写操作中, 写依赖于读, 那么如果写前读的内容发生变化, 就会出现更新丢失
## 原子写
一般对单个对象会提供原子写功能, 此时一般是上一个X锁, 这种形式被称为cursor stability, 即对事务中任何一次单个对象修改进行上锁, 但是不保证整体的一致性, 即比RR弱
如果是只上短S锁, 那就是RC, 下次再读/写的时候, 数据已经不同了(这样就冲突了)

更暴力的原子写实现还有, 直接让一个线程管理一个对象的写, 实现局部可串行化

## 显式上锁
直接用for update显式上锁, 避免写写冲突

## 检测更新丢失
可以认为是乐观方式, 允许写并发, 但是做写冲突检测, 并检测出其中的更新丢失, 然后进行重试

在SI级别上, 可以高效地检测更新丢失, oracle, pg等都可以, 但是mysql的innodb不做这个检测, 一般来说, 快照隔离都要能做这个, 所以可以说mysql没有严格的SI

自动检测可以降低心智负担, 避免隐藏bug

## CAS
不支持事务的数据库, 有时支持CAS, 也可以避免一部分更新丢失, 但是如果C的时候读到快照上去了, 那就还是会丢失

## 多副本冲突
此时更新丢失更麻烦, 因为写入都已经成功了, 无法拒绝, 只能进行冲突解决, 一般来说, 可以用多版本维护内容, 然后制定规则进行冲突解决

如果操作满足交换律, 原子操作是可以并发的, 可以正常合并

解决冲突是很麻烦的, 默认使用后者胜, 虽然会更新丢失, 但是没办法, 只能这样, 也是大部分数据库使用的方式
# write skew

显然, 写偏斜问题本质上是多对象的读写冲突, 根本上, 是没能及时获取另一个事务的修改, 还能成功写入

或者说: 一个事务的写入导致另一个事务的读取失效(无意义), 导致其写入策略错误(与业务不一致)

这是基于mvcc的SI特有的问题, 就是不上锁才会这样
- 否则根本不会让他写入
- 读的时候来自一个不变的快照,
- 但是写的时候写的又是不同的东西, 所以没有版本控制

## 解决方案:
难以解决, 因为多对象
在mvcc实现中, 要避免write skew, 需要可串行化, 或者用for update

# 幻读与write skew

幻读是显然会导致write skew的, 如果发现有的数据不存在, 我就去写别的另一个数据, 那此时如果查的数据有了, 那另一个数据是不受版本控制的.

就算是for update, 只是行锁的话, 对于幻读导致的write skew , 还是解决不了

只能物化, 进而gap lock

# Ref.
[SQL 异象 | Spring Boot 持久化最佳实践](https://levid-gc.github.io/spring-boot-persistence-best-practices/blog/sql-phenomena/)
[数据库事务发展史和 SSI 隔离级别原理 | EagleBear2002 的博客](https://eaglebear2002.github.io/46771/)
[mysql - 快照隔离级别原理 | StoneDB 技术分享 #1 - 个人文章 - SegmentFault 思否](https://segmentfault.com/a/1190000044119067)